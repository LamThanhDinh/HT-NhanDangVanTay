import http.server
import socketserver
import json
import base64
import cv2 as cv
import numpy as np
from urllib.parse import parse_qs, urlparse
import os
from io import BytesIO

from utils.normalization import normalize
from utils.segmentation import create_segmented_and_variance_images
from utils import orientation
from utils.frequency import ridge_freq
from utils.gabor_filter import gabor_filter
from utils.skeletonize import skeletonize
from utils.crossing_number import calculate_minutiaes
from utils.poincare import calculate_singularities

PORT = 8080

def image_to_base64(img):
    """Chuyá»ƒn áº£nh numpy array sang base64 string"""
    # Äáº£m báº£o áº£nh lÃ  uint8
    if img.dtype != np.uint8:
        # Normalize vá» range 0-255 náº¿u cáº§n
        if img.max() <= 1.0:
            img = (img * 255).astype(np.uint8)
        else:
            img = np.clip(img, 0, 255).astype(np.uint8)
    
    # Convert sang RGB náº¿u lÃ  grayscale
    if len(img.shape) == 2:
        img = cv.cvtColor(img, cv.COLOR_GRAY2RGB)
    
    _, buffer = cv.imencode('.png', img)
    img_base64 = base64.b64encode(buffer).decode('utf-8')
    return f"data:image/png;base64,{img_base64}"

def process_fingerprint(input_img):
    """Xá»­ lÃ½ áº£nh vÃ¢n tay vÃ  tráº£ vá» tá»«ng bÆ°á»›c (8 bÆ°á»›c + composite)"""
    block_size = 16
    steps = []
    
    # BÆ¯á»šC 1: áº¢nh gá»‘c
    steps.append({
        'step': 1,
        'name': 'ğŸ–¼ï¸ áº¢nh Gá»‘c (Original Image)',
        'description': 'ÄÃ¢y lÃ  áº£nh vÃ¢n tay ban Ä‘áº§u Ä‘Æ°á»£c Ä‘á»c tá»« cáº£m biáº¿n hoáº·c file. áº¢nh Ä‘Æ°á»£c chuyá»ƒn sang dáº¡ng grayscale (áº£nh xÃ¡m) Ä‘á»ƒ chuáº©n bá»‹ cho cÃ¡c bÆ°á»›c xá»­ lÃ½ tiáº¿p theo.',
        'image': image_to_base64(input_img),
        'details': f'ğŸ“ KÃ­ch thÆ°á»›c: {input_img.shape[1]} Ã— {input_img.shape[0]} pixels | ğŸ¨ Format: 8-bit Grayscale'
    })
    
    # BÆ¯á»šC 2: Chuáº©n hÃ³a
    normalized_img = normalize(input_img.copy(), float(100), float(100))
    steps.append({
        'step': 2,
        'name': 'âš–ï¸ Chuáº©n hÃ³a (Normalization)',
        'description': 'Äiá»u chá»‰nh Ä‘á»™ sÃ¡ng vÃ  Ä‘á»™ tÆ°Æ¡ng pháº£n cá»§a áº£nh vá» má»™t chuáº©n thá»‘ng nháº¥t (mean=100, variance=100). Loáº¡i bá» áº£nh hÆ°á»Ÿng cá»§a lá»±c áº¥n ngÃ³n tay, Ä‘á»™ áº©m da, vÃ  Ä‘iá»u kiá»‡n chiáº¿u sÃ¡ng khÃ¡c nhau giá»¯a cÃ¡c láº§n quÃ©t.',
        'image': image_to_base64(normalized_img),
        'details': 'ğŸ“Š Mean = 100 | ğŸ“ˆ Variance = 100 | ğŸ¯ Má»¥c Ä‘Ã­ch: Chuáº©n hÃ³a cÆ°á»ng Ä‘á»™ pixel'
    })
    
    # BÆ¯á»šC 3: PhÃ¢n Ä‘oáº¡n
    segmented_img, normim, mask = create_segmented_and_variance_images(normalized_img, block_size, 0.2)
    steps.append({
        'step': 3,
        'name': 'âœ‚ï¸ PhÃ¢n Ä‘oáº¡n (Segmentation)',
        'description': 'TÃ¡ch vÃ¹ng cÃ³ vÃ¢n tay (foreground/ROI) ra khá»i vÃ¹ng ná»n trá»‘ng (background). Sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p variance-based: vÃ¹ng cÃ³ vÃ¢n tay cÃ³ Ä‘á»™ biáº¿n thiÃªn cao (ridge-valley alternation), vÃ¹ng ná»n cÃ³ Ä‘á»™ biáº¿n thiÃªn tháº¥p.',
        'image': image_to_base64(segmented_img),
        'details': f'ğŸ”² Block size: {block_size}Ã—{block_size} pixels | ğŸ“‰ Threshold: 0.2 Ã— std(image) | âœ¨ Morphological refinement'
    })
    
    # BÆ¯á»šC 4: Äá»‹nh hÆ°á»›ng
    angles = orientation.calculate_angles(normalized_img, W=block_size, smoth=False)
    orientation_img = orientation.visualize_angles(segmented_img, mask, angles, W=block_size)
    steps.append({
        'step': 4,
        'name': 'ğŸ§­ Äá»‹nh hÆ°á»›ng (Orientation Field)',
        'description': 'TÃ­nh toÃ¡n hÆ°á»›ng (gÃ³c) cá»§a cÃ¡c Ä‘Æ°á»ng vÃ¢n táº¡i má»—i vÃ¹ng block. CÃ¡c Ä‘Æ°á»ng mÃ u xanh lÃ¡ cÃ¢y chá»‰ hÆ°á»›ng vÃ¢n tay cháº¡y. ThÃ´ng tin nÃ y ráº¥t quan trá»ng cho bÆ°á»›c lá»c Gabor.',
        'image': image_to_base64(orientation_img),
        'details': 'ğŸ¨ MÃ u xanh = hÆ°á»›ng vÃ¢n | ğŸ“ PhÆ°Æ¡ng phÃ¡p: Gradient-based (Sobel) | ğŸ”¢ Block size: 16Ã—16',
        'legend': '<span style="color: #00FF00; font-weight: bold;">â”â”â” HÆ°á»›ng vÃ¢n (Green)</span>'
    })
    
    # TÃ­nh frequency (khÃ´ng hiá»ƒn thá»‹ riÃªng, chá»‰ dÃ¹ng cho Gabor)
    freq = ridge_freq(normim, mask, angles, block_size, kernel_size=5, minWaveLength=5, maxWaveLength=15)
    
    # BÆ¯á»šC 5: Lá»c Gabor
    gabor_img = gabor_filter(normim, angles, freq)
    steps.append({
        'step': 5,
        'name': 'ğŸ›ï¸ Lá»c Gabor (Gabor Filter)',
        'description': 'Bá»™ lá»c quan trá»ng nháº¥t! Gabor filter káº¿t há»£p thÃ´ng tin vá» hÆ°á»›ng vÃ¢n (orientation) vÃ  táº§n sá»‘ vÃ¢n (frequency) Ä‘á»ƒ lÃ m ná»•i báº­t Ä‘Æ°á»ng vÃ¢n, giáº£m nhiá»…u, vÃ  káº¿t ná»‘i cÃ¡c Ä‘Æ°á»ng vÃ¢n bá»‹ Ä‘á»©t gÃ£y. áº¢nh sau bÆ°á»›c nÃ y cÃ³ ridge rÃµ nÃ©t nháº¥t.',
        'image': image_to_base64(gabor_img),
        'details': 'ğŸšï¸ Filter káº¿t há»£p orientation + frequency | âš™ï¸ Parameters: Ïƒâ‚“=Ïƒáµ§=0.65/f | â­ BÆ°á»›c quan trá»ng nháº¥t!'
    })
    
    # BÆ¯á»šC 6: LÃ m má»ng
    thin_image = skeletonize(gabor_img)
    steps.append({
        'step': 6,
        'name': 'ğŸ¦´ LÃ m má»ng (Skeletonization)',
        'description': 'Thu gá»n cÃ¡c Ä‘Æ°á»ng vÃ¢n tá»« Ä‘á»™ dÃ y 5-10 pixels xuá»‘ng chá»‰ cÃ²n 1 pixel (skeleton). Äiá»u nÃ y giÃºp xÃ¡c Ä‘á»‹nh chÃ­nh xÃ¡c vá»‹ trÃ­ cÃ¡c Ä‘iá»ƒm Ä‘áº·c trÆ°ng minutiae á»Ÿ bÆ°á»›c tiáº¿p theo. Sá»­ dá»¥ng thuáº­t toÃ¡n Zhang-Suen.',
        'image': image_to_base64(thin_image),
        'details': 'âš™ï¸ Algorithm: Zhang-Suen | ğŸ“ Ridge width: 1 pixel | âœ… Topology preserved'
    })
    
    # BÆ¯á»šC 7: Äiá»ƒm Ä‘áº·c trÆ°ng (Minutiae)
    minutias_img = calculate_minutiaes(thin_image)
    steps.append({
        'step': 7,
        'name': 'ğŸ”´ğŸŸ¢ Minutiae (Äiá»ƒm Ä‘áº·c trÆ°ng)',
        'description': 'PhÃ¡t hiá»‡n cÃ¡c Ä‘iá»ƒm Ä‘áº·c trÆ°ng minutiae - nhá»¯ng Ä‘iá»ƒm quan trá»ng nháº¥t Ä‘á»ƒ nháº­n dáº¡ng vÃ¢n tay. CÃ³ 2 loáº¡i: Ridge Ending (Ä‘iá»ƒm káº¿t thÃºc - mÃ u Äá») vÃ  Bifurcation (Ä‘iá»ƒm phÃ¢n nhÃ¡nh - mÃ u XANH LÃ). Sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p Crossing Number.',
        'image': image_to_base64(minutias_img),
        'details': 'ğŸ”´ Ridge Ending (CN=1) | ğŸŸ¢ Bifurcation (CN=3) | ğŸ“Š Trung bÃ¬nh: 40-60 minutiae/áº£nh | ğŸ’¾ LÆ°u: (type, x, y, Î¸)',
        'legend': '<span style="color: red; font-weight: bold;">â— Ridge Ending (Äá»)</span> &nbsp;&nbsp; <span style="color: green; font-weight: bold;">â— Bifurcation (Xanh)</span>'
    })
    
    # BÆ¯á»šC 8: Äiá»ƒm ká»³ dá»‹ (Singularities)
    singularities_img = calculate_singularities(thin_image, angles, 1, block_size, mask)
    steps.append({
        'step': 8,
        'name': 'ğŸŸ  Singularities (Äiá»ƒm ká»³ dá»‹)',
        'description': 'PhÃ¡t hiá»‡n cÃ¡c Ä‘iá»ƒm ká»³ dá»‹ (Core, Delta, Whorl) - nhá»¯ng Ä‘iá»ƒm mÃ  hÆ°á»›ng vÃ¢n tay thay Ä‘á»•i Ä‘á»™t ngá»™t. Core lÃ  tÃ¢m xoÃ¡y (Ã´ vuÃ´ng CAM), Delta lÃ  Ä‘iá»ƒm tam giÃ¡c (Ã´ vuÃ´ng Äá»), Whorl lÃ  Ä‘iá»ƒm xoÃ¡y (Ã´ vuÃ´ng TÃM). BÆ°á»›c nÃ y CHá»ˆ Äá»‚ TRá»°C QUAN HÃ“A, khÃ´ng dÃ¹ng cho matching.',
        'image': image_to_base64(singularities_img),
        'details': 'ğŸŸ§ Core (Cam) | ğŸŸ¥ Delta (Äá») | ğŸŸª Whorl (TÃ­m) | â„¹ï¸ Chá»‰ Ä‘á»ƒ hiá»ƒn thá»‹, khÃ´ng dÃ¹ng matching',
        'legend': '<span style="display:inline-block;width:18px;height:18px;border:2px solid orange;vertical-align:middle;margin-right:4px;"></span> Core (Cam) &nbsp;&nbsp;'
                  '<span style="display:inline-block;width:18px;height:18px;border:2px solid red;vertical-align:middle;margin-right:4px;"></span> Delta (Äá») &nbsp;&nbsp;'
                  '<span style="display:inline-block;width:18px;height:18px;border:2px solid purple;vertical-align:middle;margin-right:4px;"></span> Whorl (TÃ­m)'
    })
    
    # Táº O COMPOSITE IMAGE (ghÃ©p 8 áº£nh thÃ nh 2 hÃ ng Ã— 4 cá»™t)
    output_imgs = [input_img, normalized_img, segmented_img, orientation_img, gabor_img, thin_image, minutias_img, singularities_img]
    
    # Convert táº¥t cáº£ sang RGB náº¿u lÃ  grayscale
    for i in range(len(output_imgs)):
        if len(output_imgs[i].shape) == 2:
            output_imgs[i] = cv.cvtColor(output_imgs[i], cv.COLOR_GRAY2RGB)
    
    # GhÃ©p 2 hÃ ng: hÃ ng 1 (áº£nh 0-3), hÃ ng 2 (áº£nh 4-7)
    composite_img = np.concatenate([
        np.concatenate(output_imgs[:4], 1),  # HÃ ng 1: Original, Norm, Seg, Orient
        np.concatenate(output_imgs[4:], 1)   # HÃ ng 2: Gabor, Thin, Minutiae, Singularities
    ]).astype(np.uint8)
    
    # ThÃªm composite image vÃ o cuá»‘i
    steps.append({
        'step': 9,  # Composite á»Ÿ cuá»‘i cÃ¹ng
        'name': 'ğŸ¨ Káº¾T QUáº¢ Tá»”NG Há»¢P (Composite)',
        'description': 'Tá»•ng há»£p 8 bÆ°á»›c xá»­ lÃ½ trong 1 áº£nh duy nháº¥t. HÃ ng trÃªn: Original, Normalization, Segmentation, Orientation. HÃ ng dÆ°á»›i: Gabor Filter, Skeletonization, Minutiae, Singularities.',
        'image': image_to_base64(composite_img),
        'details': 'ğŸ“ Layout: 2 hÃ ng Ã— 4 cá»™t | ğŸ–¼ï¸ Táº¥t cáº£ 8 bÆ°á»›c trong 1 áº£nh | ğŸ’¾ Dá»… lÆ°u vÃ  so sÃ¡nh'
    })
    
    return steps

class MyHTTPRequestHandler(http.server.SimpleHTTPRequestHandler):
    def do_GET(self):
        if self.path == '/api/demo':
            self.handle_demo()
            return
        elif self.path == '/':
            self.path = '/index.html'
        return http.server.SimpleHTTPRequestHandler.do_GET(self)
    
    def do_POST(self):
        if self.path == '/api/process':
            self.handle_upload()
            return
        self.send_response(404)
        self.send_header('Content-type', 'application/json')
        self.end_headers()
        self.wfile.write(json.dumps({'error': 'Not found'}).encode())
    
    def handle_demo(self):
        """Xá»­ lÃ½ áº£nh demo"""
        try:
            # TÃ¬m áº£nh demo
            demo_paths = [
                './data/dataset/test/DB3',
                './data/dataset/test/DB1',
                './data/dataset/train/DB3',
                './data/dataset/train/DB1',
            ]
            
            demo_img_path = None
            for path in demo_paths:
                if os.path.exists(path):
                    files = [f for f in os.listdir(path) if f.endswith(('.png', '.jpg', '.bmp', '.tif'))]
                    if files:
                        demo_img_path = os.path.join(path, files[0])
                        break
            
            if demo_img_path is None:
                self.send_json_response({'error': 'KhÃ´ng tÃ¬m tháº¥y áº£nh demo'}, 404)
                return
            
            input_img = cv.imread(demo_img_path, cv.IMREAD_GRAYSCALE)
            steps = process_fingerprint(input_img)
            
            self.send_json_response({'success': True, 'steps': steps})
        except Exception as e:
            self.send_json_response({'error': str(e)}, 500)
    
    def handle_upload(self):
        """Xá»­ lÃ½ upload áº£nh"""
        try:
            content_length = int(self.headers['Content-Length'])
            post_data = self.rfile.read(content_length)
            
            # Parse multipart form data - tÃ¬m boundary
            content_type = self.headers.get('Content-Type', '')
            if 'boundary=' not in content_type:
                self.send_json_response({'error': 'Invalid content type'}, 400)
                return
                
            boundary = content_type.split('boundary=')[1].encode()
            parts = post_data.split(b'--' + boundary)
            
            image_data = None
            for part in parts:
                if b'Content-Type: image' in part or b'filename=' in part:
                    try:
                        # TÃ¡ch header vÃ  data
                        headers_and_data = part.split(b'\r\n\r\n', 1)
                        if len(headers_and_data) == 2:
                            image_data = headers_and_data[1].rstrip(b'\r\n')
                            if len(image_data) > 100:  # Äáº£m báº£o cÃ³ data
                                break
                    except:
                        continue
            
            if image_data is None or len(image_data) < 100:
                self.send_json_response({'error': 'KhÃ´ng tÃ¬m tháº¥y áº£nh trong request'}, 400)
                return
            
            # Decode áº£nh
            nparr = np.frombuffer(image_data, np.uint8)
            input_img = cv.imdecode(nparr, cv.IMREAD_GRAYSCALE)
            
            if input_img is None:
                self.send_json_response({'error': 'KhÃ´ng thá»ƒ Ä‘á»c áº£nh. Vui lÃ²ng upload file áº£nh há»£p lá»‡'}, 400)
                return
            
            steps = process_fingerprint(input_img)
            self.send_json_response({'success': True, 'steps': steps})
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            self.send_json_response({'error': f'Lá»—i server: {str(e)}'}, 500)
    
    def send_json_response(self, data, status=200):
        self.send_response(status)
        self.send_header('Content-type', 'application/json')
        self.send_header('Access-Control-Allow-Origin', '*')
        self.end_headers()
        self.wfile.write(json.dumps(data).encode())

if __name__ == '__main__':

    import sys
    def visualize_local(image_path):
        import matplotlib.pyplot as plt
        import re
        print("\n" + "=" * 70)
        print("ğŸ”¬ PHÃ‚N TÃCH PIPELINE VÃ‚N TAY - LOCAL MODE")
        print("=" * 70)
        print(f"ğŸ“¸ Äang xá»­ lÃ½: {image_path}")
        input_img = cv.imread(image_path, cv.IMREAD_GRAYSCALE)
        if input_img is None:
            print(f"âŒ KhÃ´ng thá»ƒ Ä‘á»c áº£nh: {image_path}")
            return
        steps = process_fingerprint(input_img)
        composite_base64 = steps[-1]['image']
        img_data = re.sub('^data:image/.+;base64,', '', composite_base64)
        img_bytes = base64.b64decode(img_data)
        nparr = np.frombuffer(img_bytes, np.uint8)
        composite_img = cv.imdecode(nparr, cv.IMREAD_COLOR)
        composite_rgb = cv.cvtColor(composite_img, cv.COLOR_BGR2RGB)
        # Hiá»ƒn thá»‹ legend phÃ­a trÃªn áº£nh
        import matplotlib.patches as mpatches
        plt.figure(figsize=(20, 10))
        plt.title('Pipeline Xá»­ LÃ½ VÃ¢n Tay - 8 BÆ°á»›c\nHÃ ng 1: (1) Original | (2) Normalized | (3) Segmented | (4) Orientation\nHÃ ng 2: (5) Gabor | (6) Thinning | (7) Minutiae | (8) Singularities', fontsize=14, pad=30)
        plt.imshow(composite_rgb)
        plt.axis('off')
        # ChÃº thÃ­ch báº±ng patch vuÃ´ng mÃ u
        legend_handles = [
            mpatches.Patch(color='red', label='Minutiae: ğŸ”´ Ridge Ending'),
            mpatches.Patch(color='green', label='ğŸŸ¢ Bifurcation'),
            mpatches.Patch(color=(1.0, 0.65, 0), label='Singularities: ğŸŸ§ Core (Cam)'),
            mpatches.Patch(color='magenta', label='ğŸŸª Whorl (TÃ­m)'),
            mpatches.Patch(color='darkred', label='ğŸŸ¥ Delta (Äá»)'),
        ]
        plt.legend(handles=legend_handles, loc='upper center', bbox_to_anchor=(0.5, 1.08), ncol=3, fontsize=13, frameon=False)
        plt.tight_layout(rect=[0, 0, 1, 0.93])
        plt.show()
        # Hiá»ƒn thá»‹ tá»«ng bÆ°á»›c riÃªng láº»
        fig, axes = plt.subplots(2, 4, figsize=(20, 10))
        axes = axes.flatten()
        for i, step_data in enumerate(steps[:8]):
            img_data = re.sub('^data:image/.+;base64,', '', step_data['image'])
            img_bytes = base64.b64decode(img_data)
            nparr = np.frombuffer(img_bytes, np.uint8)
            img = cv.imdecode(nparr, cv.IMREAD_COLOR)
            img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)
            axes[i].imshow(img_rgb)
            axes[i].set_title(step_data['name'], fontsize=10)
            axes[i].axis('off')
        # ChÃº thÃ­ch báº±ng patch vuÃ´ng mÃ u cho tá»«ng bÆ°á»›c
        fig.legend(handles=legend_handles, loc='upper center', bbox_to_anchor=(0.5, 1.08), ncol=3, fontsize=13, frameon=False)
        plt.tight_layout(rect=[0, 0, 1, 0.93])
        plt.show()

    if len(sys.argv) > 1 and sys.argv[1] != 'server':
        visualize_local(sys.argv[1])
    else:
        Handler = MyHTTPRequestHandler
        print("=" * 70)
        print("ğŸš€ KHá»I Äá»˜NG SERVER Xá»¬ LÃ VÃ‚N TAY")
        print("=" * 70)
        print(f"ğŸ“ Má»Ÿ trÃ¬nh duyá»‡t vÃ  truy cáº­p: http://localhost:{PORT}")
        print("=" * 70)
        print("ğŸ’¡ Nháº¥n Ctrl+C Ä‘á»ƒ dá»«ng server")
        print("=" * 70)
        with socketserver.TCPServer(("", PORT), Handler) as httpd:
            try:
                httpd.serve_forever()
            except KeyboardInterrupt:
                print("\nğŸ‘‹ ÄÃ£ dá»«ng server!")
